import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import sys
np.set_printoptions(threshold=sys.maxsize)
np.set_printoptions(linewidth=np.nan)
import os
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset
from torch.optim.lr_scheduler import StepLR


# 0) Load data
# Defining class for loading data
class IsingDataset(Dataset):
    def __init__(self, img_dir, label_dir):
        #self.img_labels = torch.load(label_dir)
        #self.img_data = torch.load(img_dir)
        self.img_labels = torch.load(label_dir)*2-1
        image = torch.load(img_dir) 
        image = transforms.functional.rotate(image, 90)/4 + transforms.functional.rotate(image, 180)/4 + transforms.functional.rotate(image, 270)/4 + image/4
        #image_tmp = image*0
        #for i in range(64):
        #    for j in range(64):
        #        image_tmp += torch.roll(image, shifts=(i,j), dims=(-1, -2))
        #self.img_data = image_tmp/4096
        self.img_data = image
        self.transform = None

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        image = self.img_data[idx]
        label = self.img_labels[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

# Defining function for calculating accuracy
def test_accuracy(net, testloader, output_label=None, device="cpu"):
    correct = 0
    total = 0
    with torch.no_grad():
        if np.any(output_label) == None: # if diff_array is not given, then return accuracy and do not store diff_array
            for i, (images, labels) in enumerate(testloader):
                images, labels = images.to(device), (labels).to(device)
                outputs = net(images)
                predicted = outputs
                total += labels.size(0)
                for j, (k, l) in enumerate(zip(predicted,labels)):
                    diff = abs(k-l[0]).item()
                    correct += (diff < 0.05)
                    #correct += (abs(predicted.item() - labels.item()) < 0.01)
        else: # if diff_array is given, then return accuracy and store diff_array
            for i, (images, labels) in enumerate(testloader):
                images, labels = images.to(device), (labels).to(device)
                outputs = net(images)
                predicted = outputs
                total += labels.size(0)
                for j, (k, l) in enumerate(zip(predicted,labels)):
                    diff = abs(k-l[0]).item()
                    correct += (diff < 0.05)
                    output_label[i*test_batch_size+j, 0] = l[0].item()
                    output_label[i*test_batch_size+j, 1] = l[1].item()
                    output_label[i*test_batch_size+j, 2] = l[2].item()
                    output_label[i*test_batch_size+j, 3] = k.item()

    return correct / total, output_label

# Defining function for loading data
def load_data(grid_dir="./grid_data", committor_dir="./committor_data"):    
    dataset = IsingDataset(grid_dir, committor_dir)

    train_size = int(0.8 * len(dataset))
    test_size = len(dataset) - train_size
    trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])

    # for testing
    #train_size = 120
    #test_size = len(dataset) - train_size
    #trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])
    #train_size = 100
    #test_size = 20
    #trainset, testset = torch.utils.data.random_split(trainset, [train_size, test_size])
    return trainset, testset, test_size

# 1) Model
class ConvNet(nn.Module):
    def __init__(self):
        super(ConvNet, self).__init__()
        # fully connected layers
        self.fc1 = nn.Linear(2**13, 256)
        self.fc2 = nn.Linear(256, 64)
        self.fc3 = nn.Linear(64, 1)

        # final output
        self.final = nn.Linear(2,1)

        # pooling
        self.pool = nn.MaxPool2d(2,2)

        # convolution layers
        self.conv1 = nn.Conv2d(1, 1, 3, padding=[1,1], padding_mode="circular") # Maybe pad to 10 cause area of cluster
        self.conv2 = nn.Conv2d(1, 2**7, 3, padding=[1,1], padding_mode="circular")

        # drop out
        self.drop = nn.Dropout(p=0.1)

    def forward(self, x):
        # layer 1
        x = F.leaky_relu(self.conv1(x))
        x = self.pool(x)
        # layer 2
        x = F.leaky_relu(self.conv1(x))
        x = self.pool(x)
        # layer 3
        x = F.leaky_relu(self.conv2(x))
        x = self.pool(x) # (2**3)**2

        # flatten
        x = x.view(-1, 2**13)
        
        # fully connected layer
        x = F.leaky_relu(self.fc1(x))
        x = self.drop(x)
        x = F.leaky_relu(self.fc2(x))
        x = self.drop(x)
        x = self.fc3(x)
        return F.sigmoid(x)*2-1
    
class LinNet(nn.Module):
    def __init__(self):
        super(LinNet, self).__init__()
        # fully connected layers
        self.fc1 = nn.Linear(64*64, 64)
        self.fc2 = nn.Linear(64, 16)
        self.fc3 = nn.Linear(16, 1)

        # drop out
        self.drop = nn.Dropout(p=0.2)

    def forward(self, x):
        # flatten
        x = x.view(-1, 64*64)
        # fully connected layer
        x = F.leaky_relu(self.fc1(x))
        x = self.drop(x)
        x = F.leaky_relu(self.fc2(x))
        x = self.drop(x)
        x = self.fc3(x)
        return F.sigmoid(x)*2-1

# Device configuration and setting up network
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device_cpu = torch.device('cpu')

#net = ConvNet().to(device)
#net_cpu = ConvNet().to(device_cpu)  

net = ConvNet().to(device)
net_cpu = ConvNet().to(device_cpu)  

# Printing number of parameters
total_params = sum(p.numel() for p in net.parameters())
print("Parameters: ", total_params)
#exit()

# 2) Hyper-parameters, loss and optimizer, data loading
num_epochs = 100
learning_rate = 1e-3
weight_decay = 1e-5
train_batch_size = 100
test_batch_size = 10

# Loss and optimizer
criterion = nn.MSELoss(reduction='mean')
optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)
scheduler = StepLR(optimizer, step_size=1, gamma=0.5)

# Loading data
#trainset, testset = load_data("cluster_grid_data_1", "cluster_data_1")
trainset, testset, test_size = load_data()
trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, num_workers=2, batch_size=train_batch_size)
testloader = torch.utils.data.DataLoader(testset, shuffle=False, num_workers=2, batch_size=test_batch_size)

# 3) Training loop
PATH = './model.pth'

# Initializing counters
accuracy = 0
revert_to_checkpoint = 0
revert_limit = 0
revert_break = 0
epoch = 0
loss_offset = 0
min_loss = np.inf
lr_power = 0

# checkpoint system
checkpoint = 1

# reset system
reset = 1

# storage for loss
loss_arr = np.zeros(num_epochs)

# Loading model
load = 0
if load == 1:
    checkpoint_model = torch.load(PATH)
    net.load_state_dict(checkpoint_model['model_state_dict'])
    optimizer.load_state_dict(checkpoint_model['optimizer_state_dict'])
    epoch = checkpoint_model['epoch']
    accuracy = checkpoint_model['accuracy']
    net.eval()
    print("Loaded NN")

# Running training loop
run = 1
if run == 1:
    print('Beginning Training Loop')
    n_total_steps = np.int32(len(trainset)/train_batch_size)
    correct = 0
    while (1):
        epoch += 1
        if epoch > num_epochs or revert_break >= 10:
            print("Last epoch reached or revertion break threshold reached.")
            break
        for i, (images, labels) in enumerate(trainloader):
            images = images.to(device)
            labels = labels[:,0].to(device)
            outputs = torch.flatten(net(images))
            loss = criterion(outputs, labels)
    
            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()


        revert_to_checkpoint += 1 # Incrementing checkpoint counter
        test_loss = loss.item()
        loss_arr[epoch-1] = test_loss
        np.save("loss.npy", loss_arr)
        # Test loss for reset
        if test_loss > 0.1 and epoch == 20 and reset == 1: # Resetting optimizer if accuracy is too low
            epoch = 1
            net = ConvNet().to(device)
            print("Accuracy too low, resetting network and restarting from epoch 1.")
        # Saving checkpoint
        if (min_loss > test_loss):
            revert_to_checkpoint = 0
            revert_limit = 0
            revert_break = 0
            min_loss = test_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': net.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'accuracy': accuracy,
                }, PATH)
        # If no improvement after x epochs, revert to previous checkpoint
        if revert_to_checkpoint == 10 and checkpoint == 1 and epoch > 20:
            revert_to_checkpoint = 0
            revert_limit += 1
            lr_power += 1
            if revert_limit > 5 and checkpoint == 1: # Reset learning rate if no improvement after 10 checkpoint revertions
                revert_limit = 0
                lr_power = 0
                learning_rate = 1.25*learning_rate
                revert_break += 1
                checkpoint_model = torch.load(PATH)
                net.load_state_dict(checkpoint_model['model_state_dict'])
                optimizer.load_state_dict(checkpoint_model['optimizer_state_dict'])
                epoch = checkpoint_model['epoch']
                optimizer.param_groups[0]["lr"] = learning_rate
                print("Revertion limit reached, resetting learning rate to adjusted initial value.")
                continue
            checkpoint_model = torch.load(PATH)
            net.load_state_dict(checkpoint_model['model_state_dict'])
            optimizer.load_state_dict(checkpoint_model['optimizer_state_dict'])
            epoch = checkpoint_model['epoch']
            optimizer.param_groups[0]["lr"] = learning_rate*0.5**lr_power
            print("Checkpoint loaded. Starting from epoch: ", epoch)
        lr = optimizer.param_groups[0]["lr"]
        print (f'Epoch [{epoch}/{num_epochs}], Loss: {test_loss:.8f}, Minimum Loss: {min_loss:.6f}, Learning Rate: {lr:.10f}')


test_batch_size = 1
outputs_labels = np.zeros([test_size, 4])
testloader = torch.utils.data.DataLoader(testset, shuffle=False, num_workers=2, batch_size=test_batch_size)
net_cpu.load_state_dict(net.state_dict())
net_cpu.eval()
_, outputs_labels = test_accuracy(net_cpu, testloader, output_label=outputs_labels)
outputs_labels = (outputs_labels+1)/2

np.save("prediction_actual.npy", outputs_labels)

err_width = 0.05
std_dev = np.zeros(101)
comm_percent = 0
for i in range(101):
    index = np.where((np.round(100*outputs_labels[:,0])).astype(np.int32) == i)
    std_dev[i] = np.std(outputs_labels[index][:,-1])
    comm_percent += np.sum((abs(outputs_labels[index][:,-1]-outputs_labels[index][:,0])) < std_dev[i])

comm_percent = comm_percent/test_size*100

fig, axs = plt.subplots(1, 2)
fig.set_size_inches(12.5, 6)
axs[0].scatter(outputs_labels[:,0],outputs_labels[:,-1], s=0.75, c='red')
line = np.linspace(0, 1, 101)-0.005
axs[0].plot(line, line, c='blue')
axs[0].fill_between(line, line - std_dev, line + std_dev, alpha=0.3, step="mid")
axs[0].set_title("Committor")
axs[0].set_xlabel("Actual")
axs[0].set_ylabel("Predicted")
axs[0].text(0.01, 0.99, 'Predictions within std_dev: {}%'.format(round(comm_percent,1)))
axs[1].plot(loss_arr)
axs[1].set_title("Loss")
axs[1].set_xlabel("Epoch")
axs[1].set_ylabel("Loss")
plt.show()