import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import sys
np.set_printoptions(threshold=sys.maxsize)
np.set_printoptions(linewidth=np.nan)
import os
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset
from torch.optim.lr_scheduler import StepLR


# 0) Load data
# Defining class for loading data
class IsingDataset(Dataset):
    def __init__(self, img_dir, label_dir):
        #self.img_labels = torch.load(label_dir)
        #self.img_data = torch.load(img_dir)
        self.img_labels = torch.load(label_dir)*2-1
        image = torch.load(img_dir) 
        image = transforms.functional.rotate(image, 90)/4 + transforms.functional.rotate(image, 180)/4 + transforms.functional.rotate(image, 270)/4 + image/4
        image_tmp = image*0
        for i in range(64):
            for j in range(64):
                image_tmp += torch.roll(image, shifts=(i,j), dims=(-1, -2))
        self.img_data = image_tmp/4096
        self.transform = None

    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        image = self.img_data[idx]
        label = self.img_labels[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

# Defining function for calculating accuracy
def test_accuracy(net, testloader, output_label=None, device="cpu"):
    correct = 0
    total = 0
    with torch.no_grad():
        if np.any(output_label) == None: # if diff_array is not given, then return accuracy and do not store diff_array
            for i, (images, labels) in enumerate(testloader):
                images, labels = images.to(device), (labels).to(device)
                outputs = net(images)
                predicted = outputs
                total += labels.size(0)
                for j, (k, l) in enumerate(zip(predicted,labels)):
                    diff = abs(k-l[0]).item()
                    correct += (diff < 0.05)
                    #correct += (abs(predicted.item() - labels.item()) < 0.01)
        else: # if diff_array is given, then return accuracy and store diff_array
            for i, (images, labels) in enumerate(testloader):
                images, labels = images.to(device), (labels).to(device)
                outputs = net(images)
                predicted = outputs
                total += labels.size(0)
                for j, (k, l) in enumerate(zip(predicted,labels)):
                    diff = abs(k-l[0]).item()
                    correct += (diff < 0.05)
                    output_label[i*test_batch_size+j, 0] = l[0].item()
                    output_label[i*test_batch_size+j, 1] = k.item()

    return correct / total, output_label

# Defining function for loading data
def load_data(grid_dir="./grid_data_tmp", committor_dir="./committor_data_tmp"):    
    dataset = IsingDataset(grid_dir, committor_dir)

    train_size = int(0.8 * len(dataset))
    test_size = len(dataset) - train_size
    trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])

    # for testing
    #train_size = 120
    #test_size = len(dataset) - train_size
    #trainset, testset = torch.utils.data.random_split(dataset, [train_size, test_size])
    #train_size = 100
    #test_size = 20
    #trainset, testset = torch.utils.data.random_split(trainset, [train_size, test_size])
    return trainset, testset, test_size

# 1) Model
class ConvNet(nn.Module):
    def __init__(self):
        super(ConvNet, self).__init__()
        # fully connected layers
        self.fc1 = nn.Linear(2**13, 256)
        self.fc2 = nn.Linear(256, 64)
        self.fc3 = nn.Linear(64, 1)

        # final output
        self.final = nn.Linear(2,1)

        # pooling
        self.pool = nn.MaxPool2d(2,2)

        # convolution layers
        self.conv1 = nn.Conv2d(1, 1, 3, padding=[1,1], padding_mode="circular")
        self.conv2 = nn.Conv2d(1, 2**7, 3, padding=[1,1], padding_mode="circular")

    def forward(self, x):
        # layer 1
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        # layer 2
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        # layer 3
        x = F.relu(self.conv2(x))
        x = self.pool(x) # (2**3)**2

        # flatten
        x = x.view(-1, 2**13)
        # data loss
        x = F.dropout(x, p=0.2, training=True)
        # fully connected layer
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return F.sigmoid(x)*2-1

# Device configuration and setting up network
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
net = ConvNet().to(device)
device_cpu = torch.device('cpu')
net_cpu = ConvNet().to(device_cpu)  

# Printing number of parameters
total_params = sum(p.numel() for p in net.parameters())
print("Parameters: ", total_params)
#exit()

# 2) Hyper-parameters, loss and optimizer, data loading
num_epochs = 100
learning_rate = 1e-3
weight_decay = 0e-5
train_batch_size = 100
test_batch_size = 10

# Loss and optimizer
criterion = nn.MSELoss(reduction='mean')
optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)
scheduler = StepLR(optimizer, step_size=1, gamma=0.5)

# Loading data
#trainset, testset = load_data("cluster_grid_data_1", "cluster_data_1")
trainset, testset, test_size = load_data()
trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, num_workers=2, batch_size=train_batch_size)
testloader = torch.utils.data.DataLoader(testset, shuffle=False, num_workers=2, batch_size=test_batch_size)

# 3) Training loop
PATH = './model.pth'

# Initializing counters
accuracy = 0
revert_to_checkpoint = 0
revert_limit = 0
revert_break = 0
epoch = 0
loss_offset = 0
min_loss = np.inf

# checkpoint system
checkpoint = 1

# reset system
reset = 1

# storage for loss
loss_arr = np.zeros(num_epochs)

# Loading model
load = 0
if load == 1:
    checkpoint_model = torch.load(PATH)
    net.load_state_dict(checkpoint_model['model_state_dict'])
    optimizer.load_state_dict(checkpoint_model['optimizer_state_dict'])
    epoch = checkpoint_model['epoch']
    accuracy = checkpoint_model['accuracy']
    net.eval()
    print("Loaded NN")

# Running training loop
run = 1
if run == 1:
    print('Beginning Training Loop')
    n_total_steps = np.int32(len(trainset)/train_batch_size)
    correct = 0
    while (1):
        epoch += 1
        if epoch > num_epochs or revert_break >= 10:
            break
        if revert_limit == 5 and checkpoint == 1: # Reset learning rate if no improvement after 10 checkpoint revertions
            revert_limit = 0
            learning_rate = 0.9*learning_rate
            revert_break += 1
            optimizer.param_groups[0]["lr"] = learning_rate
            print("Revertion limit reached, resetting learning rate to initial value.")
        if accuracy < 0.05 and epoch == 20 and reset == 1: # Resetting optimizer if accuracy is too low
            epoch = 1
            optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)
            print("Accuracy too low, resetting optimizer and restarting from epoch 1.")
        for i, (images, labels) in enumerate(trainloader):
            images = images.to(device)
            labels = labels[:,0].to(device)
            outputs = torch.flatten(net(images))
            loss = criterion(outputs, labels)
    
            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()


        revert_to_checkpoint += 1 # Incrementing checkpoint counter
        test_loss = loss.item()
        loss_arr[epoch-1] = test_loss
        np.save("loss.npy", loss_arr)
        # Test accuracy
        net_cpu.load_state_dict(net.state_dict())
        net_cpu.eval()
        accuracy, _ = test_accuracy(net_cpu, testloader)
        lr = scheduler.optimizer.param_groups[0]['lr']
        # Saving checkpoint
        if (min_loss > test_loss):
            revert_to_checkpoint = 0
            revert_limit = 0
            revert_break = 0
            min_loss = test_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': net.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'accuracy': accuracy,
                }, PATH)
        print (f'Epoch [{epoch}/{num_epochs}], Loss: {test_loss:.8f}, Current Accuracy: {accuracy*100:.1f}%, Minimum Loss: {min_loss:.6f}, Learning Rate: {lr:.10f}')
        # If no improvement after x epochs, revert to previous checkpoint
        if revert_to_checkpoint == 10 and checkpoint == 1 and epoch > 20:
            revert_to_checkpoint = 0
            revert_limit += 1
            checkpoint_model = torch.load(PATH)
            net.load_state_dict(checkpoint_model['model_state_dict'])
            optimizer.load_state_dict(checkpoint_model['optimizer_state_dict'])
            epoch = checkpoint_model['epoch']
            scheduler.step()
            min_loss = 1.05*min_loss
            print("Checkpoint loaded. Starting from epoch: ", epoch)

#loss_arr = np.load("loss.npy")
#plt.plot(loss_arr[1:])
#plt.xlabel("Epoch")
#plt.ylabel("BCE Loss")
#plt.show()

test_batch_size = 1
outputs_labels = np.zeros([test_size, 2])
testloader = torch.utils.data.DataLoader(testset, shuffle=False, num_workers=2, batch_size=test_batch_size)
_, outputs_labels = test_accuracy(net_cpu, testloader, output_label=outputs_labels)
outputs_labels = (outputs_labels+1)/2

err_width = 0.05

fig, axs = plt.subplots(1, 2)
fig.set_size_inches(12.5, 6)
axs[0].scatter(outputs_labels[:,0],outputs_labels[:,1], s=0.5, c='red')
line = np.linspace(0, 1, 50)
axs[0].plot(line, line, c='blue')
axs[0].fill_between(line, line - err_width, line + err_width, alpha=0.2)
axs[0].set_title("Committor")
axs[0].set_xlabel("Actual")
axs[0].set_ylabel("Predicted")
axs[1].plot(loss_arr)
axs[1].set_title("Loss")
plt.show()